{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83045d84",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d2cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerías necesarias para desarrollar el análisis\n",
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.metrics import mean_squared_error, auc, log_loss, roc_auc_score, accuracy_score, confusion_matrix, classification_report, f1_score, recall_score, precision_score, make_scorer\n",
    "import random as python_random\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.stats import ks_2samp\n",
    "import scorecardpy as sc\n",
    "#import openpyxl\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, PowerTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.pipeline import make_pipeline, Pipeline \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, log_loss, roc_auc_score, accuracy_score, confusion_matrix, classification_report, f1_score, recall_score, precision_score, make_scorer\n",
    "\n",
    "from sklearn.model_selection import KFold, ShuffleSplit, LeaveOneOut, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost\n",
    "\n",
    "import sys\n",
    "import notebook\n",
    "import jupyterlab\n",
    "\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9bd0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "# Carga el .env más cercano hacia arriba en el árbol\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Raíz del proyecto = carpeta que contiene el .env\n",
    "PROJECT_ROOT = Path(find_dotenv()).parent\n",
    "\n",
    "# DATA_PATH puede ser relativo (./data) o absoluto; aquí lo resolvemos desde el root\n",
    "DATA_PATH = (PROJECT_ROOT / os.environ.get(\"DATA_PATH\", \"data\")).resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f138c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, platform\n",
    "print(sys.executable)\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fadd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)   # muestra todas las columnas\n",
    "pd.set_option(\"display.width\", 0)            # usa el ancho de la celda de Jupyter\n",
    "pd.set_option(\"display.max_colwidth\", None)  # no truncar el contenido de celdas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378963b7",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_target = 'anula'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116a24ff",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dbced3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39aed2a1",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e47e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_ROOT = Path.cwd().parent \n",
    "sys.path.insert(0, str(PROJ_ROOT / \"src\"))\n",
    "\n",
    "\n",
    "# Verifica\n",
    "print(\"Añadido a sys.path:\", sys.path[0])\n",
    "\n",
    "from utils.data_cleaning import clean_canal_entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064aa121",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(os.environ[\"DATA_PATH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3738108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anulaciones\n",
    "file_tab = DATA_PATH / \"df_anulaciones_clean.csv\"\n",
    "df_anulaciones_clean = pd.read_csv(file_tab)\n",
    "df_anulaciones_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sociodemográfica\n",
    "#file_tab = DATA_PATH / \"df_sociodemo_clean.csv\"\n",
    "#df_sociodemo_clean = pd.read_csv(file_tab)\n",
    "\n",
    "#print(df_sociodemo_clean.shape)\n",
    "#df_sociodemo_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f606b",
   "metadata": {},
   "source": [
    "# Revision variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a49947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35ed00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in vars_num:\n",
    "    s = df_anulaciones_clean[feature]\n",
    "    n_total = s.size\n",
    "    s_valid = s.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    n_valid = s_valid.size\n",
    "    n_nulls = n_total - n_valid\n",
    "\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    sns.histplot(x=s_valid, kde=True, bins=50)\n",
    "    plt.title(f\"{feature} — {n_valid} datos de {n_total} (nulos={n_nulls})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e47e73",
   "metadata": {},
   "source": [
    "# Imputacion de variables\n",
    "- Tratamiento de outliers - Imptuar a nulls?\n",
    "- Categoricas a WOE\n",
    "- Ver si imputar nulls o dejarlos tal cual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513306a8",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adeslas-interview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
